#第一部分
##建立爬虫
###这一节关注网络爬虫的基本机制：怎样从网络服务器中请求信息，以及怎样以一种自动的方式开始与网页交互。最终，你将会轻易地遨游于网络之间，建立能够从一个域名跳转到另一个域名的爬虫，收集信息，为以后使用它们存储信息。
###坦率地讲，如果你想以小的投资来获得更大的收益，网络爬虫是一个值得进入的领域。你遇到的90%的网络爬虫项目都是基于接下来六章用到的技术。本节则介绍大众所认为的网络爬虫的含义
#####从某个域名获得HTML数据
#####为目标信息解析数据
#####存储目标信息
#####接着，可以在其他网页重复该步骤
###这部分会使得你在进入第二部分更复杂的项目之前给你坚实的基础。不要因此认为第一部分没有后半部分那些高级的项目重要。当你在写网络爬虫程序时，你会频繁地使用第一章讲述的技巧。
#第一章
##你的第一个爬虫
###当你接触爬虫时，你就会理解浏览器为我们做的这些微小的工作。网页，如果没有HTML格式，CSS样式，JavaScript执行，图片加载，初看会令人生畏，但是在这一章以及接下来的一章里，我们将涉及到在没有浏览器的帮助下转换和解释数据。
###本章通过讲解基本的向网络服务器发送特定请求以获得指定网页，读取网页输出的HTML文档，进行一些简单的数据提取来获得我们需要的内容。
##连接
###假设你并没有花费太多精力去了解网络系统或者网络安全，互联网的运行机制对你来说或许有些难以理解。我们不想去准确地搞清楚，当我们打开浏览器并且登陆谷歌时，网络一直在工作（这段不太会翻译）。事实上，我会认为，（这一段也不太会翻译）
###为了让你基本了解你的浏览器的工作方式，我尝试使用了下面这个例子。Alice拥有一台网络服务器，Bob正在使用自己的电脑试图连接到Alice的服务器上。当一台机器相与另一台机器通信时，会发生下面的交换过程：
####1.Bob的计算机发送一串01位，是由线上电压的高低值表示的。这些基本位组成了信息，包含标头和主体。标头包含他本地路由器的Mac地址
####2.Bob的本地路由器接收到这些01串， 从Bob自己的Mac地址将它们解释成一个包，并且指向Alice的IP地址。他的路由器标记包中自身的IP地址（翻译不准确），然后通过网络发送出去。
####3.Bob的包穿过几个过渡的服务器，这些服务器会将他的包指向朝着Alice服务器地址的正确的路径。
####4.Alice的服务器接收到这个包，以及她的IP地址
####5.Alice的服务器读取这个包在标文中的端口地址（对于网络应用大多数是80，你可以把这个端口号理解为数据包的“房间号”，而IP地址可以理解成“街道地址”），之后将它传给正确的应用--网络服务器应用。
####6.网络服务器应用从服务器处理器接收到一串数据，这些数据包含如下内容：
#####-这是一个GET请求
#####-以下一个名为index.html的文件被请求
####7.网络服务器定位到了正确的HTML文件，将它与一个新的包绑定起来发送给Bob,通过本地路由器发送，通过同样的过程传送到Bob的机器上。
###就这样，我们就有了互联网。
###所以，在这个交换过程中，哪里用到了浏览器？当然没有用到。事实上，浏览器是互联网历史上一个相对较晚的发明。（后面一句话不清楚）
###是的，浏览器是用来创建信息的包的很有用的应用，它发生这些包，将你接收到的数据翻译成漂亮的图片，声音，视频和文本。但是，浏览器只是编码，编码能被分离，并且被切分成基本的部分，可以被重写，被重用，变成我们想要的任何东西。浏览器能告诉处理器发送一个数据给应用来处理你的无线接口，但是还多语言也有相应的库来做这些操作。
###接下来让我们看看在Python中如何实现：
form urllib.request import urlopen
html = urlopen("http://pythonscraping.com/pages/page1/html")
print(html.read())
###你可以把这段代码保存为scarpetest.py然后在你的终端通过如下命令运行：